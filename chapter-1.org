#+TITLE: Chapter 1 Exercises

* Exercise 1.1
Below is a sequence of expressions. What is the result printed by the interpreter in response to each expression? Assume that the sequence is to be evaluated in the order in which it is presented.

#+begin_src scheme :eval never
  10
  (+ 5 3 4)
  (- 9 1)
  (/ 6 2)
  (+ (* 2 4) (- 4 6))
  (define a 3)
  (define b (+ a 1))
  (+ a b (* a b))
  (= a b)
  (if (and (> b a) (< b (* a b)))
      b
      a)
  (cond ((= a 4) 6)
        ((= b 4) (+ 6 7 a))
        (else 25))
  (+ 2 (if (> b a) b a))
  (* (cond ((> a b) a)
           ((< a b) b)
           (else -1))
     (+ a 1))
#+end_src

** Solution
  #+begin_example
  10
  12
  8
  3
  6


  19
  #f
  4
  16
  6
  16
  #+end_example

* Exercise 1.2
Translate the following expression into prefix form:

\[
\frac{5 + 4 + ( 2 - ( 3 - ( 6 + \frac{4}{5} ) ) )}
     {3( 6 - 2 )( 2 - 7 )}
\]

** Solution
#+begin_src scheme :results value
(/
 (+ 5 4 (- 2 (- 3 (+ 6 (/ 4 5)))))
 (* 3 (- 6 2) (- 2 7)))
#+end_src

#+RESULTS:
: -37/150

* Exercise 1.3
Define a procedure that takes three numbers as arguments and returns the sum of the squares of the two larger numbers.

** Solution
#+begin_src scheme
(define (weird-sum-of-squares a b c)
  (define x (if (> a b) a b))
  (define y (cond
             ((or (> c a) (> c b)) c)
             ((< a  b) a)
             (else b)))
  (+ (* x x) (* y y)))

(test-assert
    (=
     25
     (weird-sum-of-squares 2 3 4)
     (weird-sum-of-squares 2 4 3)
     (weird-sum-of-squares 3 2 4)
     (weird-sum-of-squares 3 4 2)
     (weird-sum-of-squares 4 2 3)
     (weird-sum-of-squares 4 3 2)))
#+end_src

* Exercise 1.4
Observe that our model of evaluation allows for combinations whose operators are compound expressions. Use this observation to describe the behavior of the following procedure:

#+begin_src scheme :eval never
(define (a-plus-abs-b a b)
  ((if (> b 0) + -) a b))
#+end_src

** Solution
The result of the if expression is the symbol for the operator applied to a and b, because of applicative-order evaluation.

* Exercise 1.5
Ben Bitdiddle has invented a test to determine whether the interpreter he is faced with is using applicative-order evaluation or normal-order evaluation. He defines the following two procedures:

#+begin_src scheme :eval never
(define (p) (p))

(define (test x y)
  (if (= x 0)
      0
      y))
#+end_src

Then he evaluates the expression

#+begin_src scheme :eval never
(test 0 (p))
#+end_src

What behavior will Ben observe with an interpreter that uses applicative-order evaluation? What behavior will he observe with an interpreter that uses normal-order evaluation? Explain your answer. (Assume that the evaluation rule for the special form if is the same whether the interpreter is using normal or applicative order: The predicate expression is evaluated first, and the result determines whether to evaluate the consequent or the alternative expression.)

** Solution
For applicative-order evaluation the interpreter will try to solve (p) indefinitely. For normal-order evaluation the result is 0.

* Exercise 1.6
Alyssa P. Hacker doesn't see why if needs to be provided as a special form. “Why can’t I just define it as an ordinary procedure in terms of cond?” she asks. Alyssa’s friend Eva Lu Ator claims this can indeed be done, and she defines a new version of if:

#+begin_src scheme :eval never
(define (new-if predicate
                then-clause
                else-clause)
  (cond (predicate 'then-clause)
        (else 'else-clause)))

(define (sqrt-iter guess x)
  (new-if (good-enough? guess x)
          guess
          (sqrt-iter (improve guess x) x)))
#+end_src

Eva demonstrates the program for Alyssa:
#+begin_example
> (new-if (= 2 3) 0 5)
$1 = 5

> (new-if (= 1 1) 0 5)
$2= 0
#+end_example

Delighted, Alyssa uses new-if to rewrite the square-root program:
#+begin_src scheme :eval never
(define (sqrt-iter guess x)
  (new-if (good-enough? guess x)
          guess
          (sqrt-iter (improve guess x) x)))
#+end_src

What happens when Alyssa attempts to use this to compute square roots? Explain.

** Solution
As new-if is a regular procedure, so, it's arguments get evaluated first and that leads to a infinite recursion of sqrt-iter. The special form if, on the other hand, evaluate the consequent only if the predicate is true, the alternative get evaluated only if otherwise.

* Exercise 1.7
The good-enough? test used in computing square roots will not be very effective for finding the square roots of very small numbers. Also, in real computers, arithmetic operations are almost always performed with limited precision. This makes our test inadequate for very large numbers. Explain these statements, with examples showing how the test fails for small and large numbers. An alternative strategy for implementing good-enough? is to watch how guess changes from one iteration to the next and to stop when the change is a very small fraction of the guess. Design a square-root procedure that uses this kind of end test. Does this work better for small and large numbers?

** Solution
#+begin_src scheme
(define (good-enough? last-guess guess)
  (< (abs (- 1 (/ last-guess guess))) 0.001))

(define (improve guess x)
  (/ (+ guess (/ x guess)) 2))

(define (sqrt-iter x last-guess guess)
  (if (good-enough? last-guess guess)
      guess
      (sqrt-iter x guess (improve guess x))))

(define (sqrt x)
  (sqrt-iter x 0.0 1.0))

(test-approximate 100000.0 (sqrt 10000000000.0) 0.001)
#+end_src


* Exercise 1.8
Newton’s method for cube roots is based on the fact that if y is an approximation to the cube root of x, then a better approximation is given by the value:

\[ \frac{x/y^2 + 2y}{3} \]

Use this formula to implement a cube-root procedure analogous to the square-root procedure. (In 1.3.4 we will see how to implement Newton’s method in general as an abstraction of these square-root and cube-root procedures.)

** Solution
#+begin_src scheme
(define (good-enough? last-guess guess)
  (< (abs (- 1 (/ last-guess guess))) 0.001))

(define (improve-cube-root-guess y x)
  (/ (+ (/ x (* y y)) (* 2 y)) 3))

(define (cube-root-iter x last-guess guess)
  (if (good-enough? last-guess guess)
      guess
      (cube-root-iter x guess (improve-cube-root-guess guess x))))

(define (cube-root x)
  (cube-root-iter x 0.0 1.0))

(test-approximate 3 (cube-root 27) 0.001)
#+end_src

* Exercise 1.9
Each of the following two procedures defines a method for adding two positive integers in terms of the procedures inc, which increments its argument by 1, and dec, which decrements its argument by 1.
#+begin_src scheme :eval never
(define (+ a b)
  (if (= a 0)
      b
      (inc (+ (dec a) b))))

(define (+ a b)
  (if (= a 0)
      b
      (+ (dec a) (inc b))))
#+end_src

Using the substitution model, illustrate the process generated by each procedure in evaluating (+ 4 5). Are these processes iterative or recursive?

** Solution
*** First procedure
#+begin_example
(+ 4 5)
(inc (+ (dec 4) 5))
(inc (+ 3 5))
(inc (inc (+ (dec 3) 5)))
(inc (inc (+ 2 5)))
(inc (inc (inc (+ (dec 2) 5))))
(inc (inc (inc (+ 1 5))))
(inc (inc (inc (inc (+ (dec 1) 5)))))
(inc (inc (inc (inc (+ 0 5)))))
(inc (inc (inc (inc 5))))
(inc (inc (inc 6)))
(inc (inc 7))
(inc 8)
9
#+end_example

*** Second procedure
#+begin_example
(+ 4 5)
(+ (dec 4) (inc 5))
(+ 3 6)
(+ (dec 3) (inc 6))
(+ 2 7)
(+ (dec 2) (inc 7))
(+ 1 8)
(+ (dec 1) (inc 8))
(+ 0 9)
9
#+end_example

* Exercise 1.10
The following procedure computes a mathematical function called Ackermann’s function.
#+begin_src scheme :eval never
(define (A x y)
  (cond ((= y 0) 0)
        ((= x 0) (* 2 y))
        ((= y 1) 2)
        (else (A (- x 1)
                 (A x (- y 1))))))
#+end_src

What are the values of the following expressions?
#+begin_src scheme :session :eval never
(A 1 10)
(A 2 4)
(A 3 3)
#+end_src

Consider the following procedures, where A is the procedure defined above:
#+begin_src scheme :eval never
(define (f n) (A 0 n))
(define (g n) (A 1 n))
(define (h n) (A 2 n))
(define (k n) (* 5 n n))
#+end_src

Give concise mathematical definitions for the functions computed by the procedures f, g, and h for positive integer values of n. For example, (k n) computes $5n^2$.

** Solution
#+begin_example
> (A 1 10)
$1 = 1024
> (A 2 4)
$2 = 65536
> (A 3 3)
$3 = 65536
#+end_example

$f(n) = 2n$

$g(n) = 2^n$

$h(n) = 2^{h(n-1)}$

* Exercise 1.11
A function f is defined by the rule that $f(n)=n$ if $n<3$ and $f(n)=f(n-1)+2f(n-2)+3f(n-3)$ if $n \ge 3$. Write a procedure that computes f by means of a recursive process. Write a procedure that computes f by means of an iterative process.

** Solution
*** Recursive
#+name: recursive
#+begin_src scheme
(define (f n)
  (if (< n 3)
      n
      (+
       (f (- n 1))
       (* 2 (f (- n 2)))
       (* 3 (f (- n 3))))))

(test-equal 0 (f 0))
(test-equal 1 (f 1))
(test-equal 2 (f 2))
(test-equal 4 (f 3))
(test-equal 11 (f 4))
(test-equal 25 (f 5))
#+end_src

*** Iterative
#+name: iterative
#+begin_src scheme
(define (f n)
  (define (f-step n-1 n-2 n-3)
    (+ n-1 (* 2 n-2) (* 3 n-3)))
  (define (f-iter n-1 n-2 n-3 count)
    (if (= count 0)
        n-1
        (f-iter (f-step n-1 n-2 n-3) n-1 n-2 (- count 1))))
  (if (< n 3)
      n
      (f-iter 2 1 0 (- n 2))))

(test-equal 0 (f 0))
(test-equal 1 (f 1))
(test-equal 2 (f 2))
(test-equal 4 (f 3))
(test-equal 11 (f 4))
(test-equal 25 (f 5))
#+end_src

* Exercise 1.12
The following pattern of numbers is called Pascal’s triangle.

#+begin_example
         1
       1   1
     1   2   1
   1   3   3   1
 1   4   6   4   1
       . . .
#+end_example

The numbers at the edge of the triangle are all 1, and each number inside the triangle is the sum of the two numbers above it. Write a procedure that computes elements of Pascal’s triangle by means of a recursive process.

** Solution
#+begin_src scheme
(define (pascal-triangle r k)
  (if (or (= r 1) (< k 2) (>= k r))
       1
       (+
        (pascal-triangle (- r 1) (- k 1))
        (pascal-triangle (- r 1) k))))

(test-equal 6 (pascal-triangle 5 3))
#+end_src

* Exercise 1.13
Prove that $Fib(n)$ is the closest integer to $\varphi^n/\sqrt{5}$ where $\varphi = (1 + \sqrt{5})/2$. Hint: Let $\psi = (1 - \sqrt{5})/2$. Use induction and the definition of the Fibonacci numbers (see 1.2.2) to prove that $Fib(n) = (\varphi^n - \psi^n) / \sqrt{5}$.

** Solution
Let $\varphi = \frac{1+\sqrt{5}}{2}$ and $\psi = \frac{1-\sqrt{5}}{2}$. If $Fib(n)$ is the nearest integer to $\frac{\varphi^n}{\sqrt{5}}$, the following inequality holds true:

\[ \left| Fib(n) - \frac{\varphi^n}{\sqrt{5}} \right| < \frac{1}{2} \]

Proposition:
\[ Fib(n) = \frac{\varphi^n}{\sqrt{5}} - \frac{\psi^n}{\sqrt{5}} \]

Demonstration:
\[
\frac{\varphi^n - \psi^n}{\sqrt{5}} =
\frac{\varphi^{n-1} - \psi^{n-1}}{\sqrt{5}} +
\frac{\varphi^{n-2} - \psi^{n-2}}{\sqrt{5}}
\]
\[
\varphi^n - \psi^n =
\varphi^{n-1} - \psi^{n-1} + \varphi^{n-2} - \psi^{n-2}
\]
\[
\varphi^n - \psi^n =
\frac{\varphi^n}{\varphi} - \frac{\psi^n}{\psi} +
\frac{\varphi^n}{\varphi^2} - \frac{\psi^n}{\psi^2}
\]
\[
\varphi^n - \psi^n =
\varphi^n \left(\frac{1}{\varphi} + \frac{1}{\varphi^2}\right) -
\psi^n \left(\frac{1}{\psi} + \frac{1}{\psi^2}\right)
\]
\[
\varphi^n - \psi^n =
\varphi^n \left( \frac{\varphi + 1}{\varphi^2} \right) -
\psi^n \left( \frac{\psi + 1}{\psi^2} \right)
\]

Since $\varphi^2 = \varphi + 1$:
\[
\varphi^2 = \varphi + 1
\]
\[
\left(\frac{1+\sqrt{5}}{2}\right)^2 = \frac{1+\sqrt{5}}{2} + 1
\]
\[
\frac{\left( 1+\sqrt{5} \right)^2}{4} = \frac{1+\sqrt{5}}{2} + 1
\]
\[
\left( 1+\sqrt{5} \right)^2 = 4\left(\frac{1+\sqrt{5}}{2} + 1 \right)
\]
\[
\left( 1+\sqrt{5} \right)^2 = 2 \left( 1+\sqrt{5} \right) + 4
\]
\[
\left( 1+\sqrt{5} \right)^2 = 2 + 2\sqrt{5} + 4
\]
\[
\left( 1+\sqrt{5} \right)^2 = 6 + 2\sqrt{5}
\]
\[
1 + 2\sqrt{5} + 5 = 6 + 2\sqrt{5}
\]
\[
6 + 2\sqrt{5} = 6 + 2\sqrt{5}
\]
\[
3 + \sqrt{5} = 3 + \sqrt{5}
\]

And $\psi^2 = \psi + 1$:
\[
\psi^2 = \psi + 1
\]
\[
\left(\frac{1-\sqrt{5}}{2}\right)^2 = \frac{1-\sqrt{5}}{2} + 1
\]
\[
\frac{\left( 1-\sqrt{5} \right)^2}{4} = \frac{1-\sqrt{5}}{2} + 1
\]
\[
\left( 1-\sqrt{5} \right)^2 = 4\left(\frac{1-\sqrt{5}}{2} + 1 \right)
\]
\[
\left( 1-\sqrt{5} \right)^2 = 2 \left( 1-\sqrt{5} \right) + 4
\]
\[
\left( 1-\sqrt{5} \right)^2 = 2 - 2\sqrt{5} + 4
\]
\[
\left( 1-\sqrt{5} \right)^2 = 6 - 2\sqrt{5}
\]
\[
1 - 2\sqrt{5} + 5 = 6 - 2\sqrt{5}
\]
\[
6 - 2\sqrt{5} = 6 - 2\sqrt{5}
\]
\[
3 - \sqrt{5} = 3 - \sqrt{5}
\]

The proposition is true. Substituting $Fib(n)$ in the original inequality:
\[
\left| \frac{\varphi^n}{\sqrt{5}} -
\frac{\psi^n}{\sqrt{5}}  -
\frac{\varphi^n}{\sqrt{5}} \right|
< \frac{1}{2}
\]
\[
\left| - \frac{\psi^n}{\sqrt{5}} \right| < \frac{1}{2}
\]

As $-1 < \psi < 0$, so $-1 < \psi^n < 1$ for any $n \in \mathbb{N} > 0$, and $\sqrt{5} > 2$, therefore $Fib(n)$ is the nearest integer to $\frac{\varphi^n}{\sqrt{5}}$.

* Exercise 1.14
Draw the tree illustrating the process generated by the count-change procedure of 1.2.2 in making change for 11 cents. What are the orders of growth of the space and number of steps used by this process as the amount to be changed increases?

** Solution
Evaluation tree:

#+INCLUDE: "1_14-tree-graph.dot" src dot :file 1_14-tree-graph.png

* Exercise 1.15
The sine of an angle (specified in radians) can be computed by making use of the approximation $\sin{x} \approx x$ if $x$ is sufficiently small, and the trigonometric identity

\[ \sin{x} = 3\sin{\frac{x}{3}} - 4\sin^3{\frac{x}{3}} \]

to reduce the size of the argument of sin. (For purposes of this exercise an angle is considered “sufficiently small” if its magnitude is not greater than 0.1 radians.) These ideas are incorporated in the following procedures:

#+begin_src scheme :eval never
(define (cube x) (* x x x))
(define (p x) (- (* 3 x) (* 4 (cube x))))
(define (sine angle)
   (if (not (> (abs angle) 0.1))
       angle
       (p (sine (/ angle 3.0)))))
#+end_src

1. How many times is the procedure p applied when (sine 12.15) is evaluated?
2. What is the order of growth in space and number of steps (as a function of a) used by the process generated by the sine procedure when (sine a) is evaluated?

** Solution
The procedure p will be applied 5 times when (sine 12.15) is evaluated (See evaluation annex). As for the order of growth, this function is a linear recursion, so it means that the space required to compute has the same order of growth of the number of steps needed to finish. The procedure evolves by successively applying the transformation $a \leftarrow \frac{a}{3}$ until $a < 0.1$. This can be expressed as the product:

\[ a\prod_{1}^{n} \frac{1}{3} < 0.1 \]

\[ 0.1 > \frac{a}{3^n} \]

Where n is the number of steps. Solving for n:

\[ 0.1(3^n) > a \]
\[ 3^n > \frac{a}{0.1} \]
\[ \log_{3}{3^n} > \log_{3}{\left(\frac{a}{0.1}\right)} \]
\[ n > \log_{3}{a} - \log_{3}{0.1} \]

Applying 12.15 $\log_{3}{12.15} - \log_{3}{0.1} \approx 4.369$ where 5 is the smallest integer that solves the inequality.

Applying $\theta$, the order of growth is $\theta(\log{a})$.

* Exercise 1.16
Design a procedure that evolves an iterative exponentiation process that uses successive squaring and uses a logarithmic number of steps, as does fast-expt. (Hint: Using the observation that $(b^{n/2})^2 = (b^2)^{n/2}$, keep, along with the exponent n and the base b, an additional state variable a, and define the state transformation in such a way that the product ab^n is unchanged from state to state. At the beginning of the process a is taken to be 1, and the answer is given by the value of a at the end of the process. In general, the technique of defining an invariant quantity that remains unchanged from state to state is a powerful way to think about the design of iterative algorithms.)

** Solution
#+begin_src scheme
(define (expt b n)
  (define (even? n) (= 0 (remainder n 2)))
  (define (expt-iter b n a)
    (cond ((= n 0) a)
          ((even? n) (expt-iter (* b b) (/ n 2) a))
          (else  (expt-iter b (- n 1) (* a b)))))
  (expt-iter b n 1))

(test-equal 1 (expt 10 0))
(test-equal 7 (expt 7 1))
(test-equal 9 (expt 3 2))
(test-equal 125 (expt 5 3))
(test-equal 625 (expt 5 4))
(test-equal 32 (expt 2 5))
(test-equal 729 (expt 3 6))
(test-equal 78125 (expt 5 7))
(test-equal 256 (expt 2 8))
(test-equal 19683 (expt 3 9))
#+end_src

* Exercise 1.17
The exponentiation algorithms in this section are based on performing exponentiation by means of repeated multiplication. In a similar way, one can perform integer multiplication by means of repeated addition. The following multiplication procedure (in which it is assumed that our language can only add, not multiply) is analogous to the expt procedure:

#+begin_src scheme :eval never
(define (* a b)
  (if (= b 0)
      0
      (+ a (* a (- b 1)))))
#+end_src

This algorithm takes a number of steps that is linear in b. Now suppose we include, together with addition, operations double, which doubles an integer, and halve, which divides an (even) integer by 2. Using these, design a multiplication procedure analogous to fast-expt that uses a logarithmic number of steps.

** Solution
#+begin_src scheme
(define (halve n) (/ n 2))
(define (multi a b)
    (cond ((= b 0) 0)
          ((even? b) (multi (+ a a) (halve b)))
          (else  (+ a (multi a (- b 1) )))))

(test-equal 0 (multi 10 0))
(test-equal 7 (multi 7 1))
(test-equal 6 (multi 3 2))
(test-equal 15 (multi 5 3))
(test-equal 20 (multi 5 4))
(test-equal 10 (multi 2 5))
(test-equal 18 (multi 3 6))
(test-equal 35 (multi 5 7))
(test-equal 16 (multi 2 8))
(test-equal 27 (multi 3 9))
#+end_src

* Exercise 1.18
Using the results of Exercise 1.16 and Exercise 1.17, devise a procedure that generates an iterative process for multiplying two integers in terms of adding, doubling, and halving and uses a logarithmic number of steps.

** Solution
#+begin_src scheme
(define (multi a b)
  (define (halve n) (/ n 2))
  (define (multi-iter a b c)
    (cond ((= b 0) c)
          ((even? b) (multi-iter (+ a a) (halve b) c))
          (else  (multi-iter a (- b 1) (+ c a)))))
  (multi-iter a b 0))

(test-equal 0 (multi 10 0))
(test-equal 7 (multi 7 1))
(test-equal 6 (multi 3 2))
(test-equal 15 (multi 5 3))
(test-equal 20 (multi 5 4))
(test-equal 10 (multi 2 5))
(test-equal 18 (multi 3 6))
(test-equal 35 (multi 5 7))
(test-equal 16 (multi 2 8))
(test-equal 27 (multi 3 9))
#+end_src

* Exercise 1.19
There is a clever algorithm for computing the Fibonacci numbers in a logarithmic number of steps. Recall the transformation of the state variables a and b in the fib-iter process of 1.2.2: $a \leftarrow a + b$ and $b \leftarrow a$. Call this transformation T, and observe that applying T over and over again n times, starting with 1 and 0, produces the pair $Fib(n + 1)$ and $Fib(n)$. In other words, the Fibonacci numbers are produced by applying $T^n$, the nth power of the transformation T, starting with the pair $(1, 0)$. Now consider T to be the special case of $p = 0$ and $q = 1$ in a family of transformations $T_{pq}$, where $T_{pq}$ transforms the pair $(a, b)$ according to $a \leftarrow bq + aq + ap$ and $b \leftarrow bp + aq$. Show that if we apply such a transformation $T_{pq}$ twice, the effect is the same as using a single transformation $T_{p'q'}$ of the same form, and compute $p'$ and $q'$ in terms of p and q. This gives us an explicit way to square these transformations, and thus we can compute $T^n$ using successive squaring, as in the fast-expt procedure. Put this all together to complete the following procedure, which runs in a logarithmic number of steps:

#+begin_src scheme :eval never
(define (fib n)
  (fib-iter 1 0 0 1 n))

(define (fib-iter a b p q count)
  (cond ((= count 0)
         b)
        ((even? count)
         (fib-iter a
                   b
                   ⟨??⟩  ;compute p'
                   ⟨??⟩  ;compute q'
                   (/ count 2)))
        (else
         (fib-iter (+ (* b q)
                      (* a q)
                      (* a p))
                   (+ (* b p)
                      (* a q))
                   p
                   q
                   (- count 1)))))
#+end_src

** Solution
#+begin_src scheme
(define (fib n)
  (fib-iter 1 0 0 1 n))

(define (fib-iter a b p q count)
  (cond ((= count 0) b)
        ((even? count)
         (fib-iter a
                   b
                   (+ (* p p) (* q q))
                   (+ (* q q) (* 2 p q))
                   (/ count 2)))
        (else
         (fib-iter (+ (* b q)
                      (* a q)
                      (* a p))
                   (+ (* b p)
                      (* a q))
                   p
                   q
                   (- count 1)))))

(test-equal 1  (fib 1))
(test-equal 1  (fib 2))
(test-equal 2  (fib 3))
(test-equal 3  (fib 4))
(test-equal 5  (fib 5))
(test-equal 8  (fib 6))
(test-equal 13 (fib 7))
(test-equal 610 (fib 15))
(test-equal 1548008755920 (fib 60))
(test-equal 2880067194370816120 (fib 90))
#+end_src

* Exercise 1.20
The process that a procedure generates is of course dependent on the rules used by the interpreter. As an example, consider the iterative gcd procedure given above. Suppose we were to interpret this procedure using normal-order evaluation, as discussed in 1.1.5. (The normal-order-evaluation rule for if is described in Exercise 1.5.) Using the substitution method (for normal order), illustrate the process generated in evaluating (gcd 206 40) and indicate the remainder operations that are actually performed. How many remainder operations are actually performed in the normal-order evaluation of (gcd 206 40)? In the applicative-order evaluation?

** Solution
For normal-order evaluation the number of remainder operations executed is 18. For applicative-order evaluation, 4.

* Exercise 1.21
Use the smallest-divisor procedure to find the smallest divisor of each of the following numbers: 199, 1999, 19999.

** Solution
#+begin_example
> (smallest-divisor 199)
$1 = 199
> (smallest-divisor 1999)
$2 = 1999
> (smallest-divisor 19999)
$3 = 7
#+end_example

* Exercise 1.22
Most Lisp implementations include a primitive called runtime that returns an integer that specifies the amount of time the system has been running (measured, for example, in microseconds). The following timed-prime-test procedure, when called with an integer n, prints n and checks to see if n is prime. If n is prime, the procedure prints three asterisks followed by the amount of time used in performing the test.

#+begin_src scheme :eval never
(define (timed-prime-test n)
  (newline)
  (display n)
  (start-prime-test n (runtime)))

(define (start-prime-test n start-time)
  (if (prime? n)
      (report-prime (- (runtime)
                       start-time))))

(define (report-prime elapsed-time)
  (display " *** ")
  (display elapsed-time))
#+end_src

Using this procedure, write a procedure search-for-primes that checks the primality of consecutive odd integers in a specified range. Use your procedure to find the three smallest primes larger than 1000; larger than 10,000; larger than 100,000; larger than 1,000,000. Note the time needed to test each prime. Since the testing algorithm has order of growth of $\theta(n)$, you should expect that testing for primes around 10,000 should take about 10 times as long as testing for primes around 1000. Do your timing data bear this out? How well do the data for 100,000 and 1,000,000 support the $\theta(n)$ prediction? Is your result compatible with the notion that programs on your machine run in time proportional to the number of steps required for the computation?

** Solution
#+begin_src scheme
(load-from-path "1_22-definitions.scm")
(define (search-for-primes start)
  (define (search-for-primes-iter n count)
    (if (> count 0)
        (search-for-primes-iter
         (+ n 2)
         (if (timed-prime-test n) (- count 1) count))))
  (search-for-primes-iter
   (if (divides? 2 start) (+ start 1) start)
   3))
#+end_src

#+begin_example
> (search-for-primes 100000)
100003 | 71004
100019 | 69836
100043 | 69686

> (search-for-primes 1000000)
1000003 | 413345
1000033 | 417740
1000037 | 417630

> (search-for-primes 10000000)
10000019 | 692164
10000079 | 673696
10000103 | 697857

> (search-for-primes 100000000)
100000007 | 1731865
100000037 | 1448142
100000039 | 1630682
#+end_example

Let m be the mean time for the three smallest primes greater than 100000 and T_n to be the measured time (in nanoseconds) to check for primality of n. If m is taken take as the standard computation time for prime test, the deviation, D_n, from the expected computation time is:

\[
D_n = T_n - m\left(\frac{\sqrt{n}}{\sqrt{100000}}\right)
\]

Observed mean:
m = 70175

|         n | T_n (ns) |           D_n |
|-----------+----------+---------------|
|   1000003 |   413345 |     191431.83 |
|   1000033 |   417740 |     195823.50 |
|   1000037 |   417630 |     195713.06 |
|  10000019 |   692164 |    -9586.6667 |
|  10000079 |   673696 |    -28056.772 |
|  10000103 |   697857 |    -3896.6140 |
| 100000007 |  1731865 |    -487263.43 |
| 100000037 |  1448142 |    -770986.76 |
| 100000039 |  1630682 |    -588446.78 |
|-----------+----------+---------------|
|  Variance |       -- | 137875470000. |
#+tblfm: $3=$2-70175*(sqrt($1)/sqrt(100000))::@11$3=vvar(@I..@II)

* Exercise 1.23
The smallest-divisor procedure shown at the start of this section does lots of needless testing: After it checks to see if the number is divisible by 2 there is no point in checking to see if it is divisible by any larger even numbers. This suggests that the values used for test-divisor should not be 2, 3, 4, 5, 6, …, but rather 2, 3, 5, 7, 9, …. To implement this change, define a procedure next that returns 3 if its input is equal to 2 and otherwise returns its input plus 2. Modify the smallest-divisor procedure to use (next test-divisor) instead of (+ test-divisor 1). With timed-prime-test incorporating this modified version of smallest-divisor, run the test for each of the 12 primes found in Exercise 1.22. Since this modification halves the number of test steps, you should expect it to run about twice as fast. Is this expectation confirmed? If not, what is the observed ratio of the speeds of the two algorithms, and how do you explain the fact that it is different from 2?

** Solution
#+begin_src scheme :eval query
(load-from-path "1_23-definitions.scm")
(search-for-primes 100000)
(search-for-primes 1000000)
(search-for-primes 10000000)
(search-for-primes 100000000)
#+end_src

#+RESULTS:
#+begin_example
100003 | 28128
100019 | 10090
100043 | 10186
1000003 | 29715
1000033 | 29531
1000037 | 29554
10000019 | 91376
10000079 | 91356
10000103 | 91318
100000007 | 289935
100000037 | 289866
100000039 | 301755
#+end_example


|         n | T_n (ns) | T2_n (ns) |   T_n/T2_n |
|-----------+----------+-----------+------------|
|    100003 |    71004 |     28128 |  1.7497720 |
|    100019 |    69836 |     10090 |  1.7098227 |
|    100043 |    69686 |     10186 |  1.8632122 |
|   1000003 |   413345 |     29715 |  3.6276472 |
|   1000033 |   417740 |     29531 |  3.7525377 |
|   1000037 |   417630 |     29554 |  3.7956357 |
|  10000019 |   692164 |     91376 |  1.1983781 |
|  10000079 |   673696 |     91356 |  1.1906816 |
|  10000103 |   697857 |     91318 |  1.1779986 |
| 100000007 |  1731865 |    289935 |  1.5999182 |
| 100000037 |  1448142 |    289866 | 0.68569829 |
| 100000039 |  1630682 |    301755 | 0.74455436 |
#+TBLFM: $4=$2/$3

* Exercise 1.24
Modify the timed-prime-test procedure of Exercise 1.22 to use fast-prime? (the Fermat method), and test each of the 12 primes you found in that exercise. Since the Fermat test has $\theta(log n)$ growth, how would you expect the time to test primes near 1,000,000 to compare with the time needed to test primes near 1000? Do your data bear this out? Can you explain any discrepancy you find?

** Solution
#+begin_src scheme :eval query
(load-from-path "1_24-definitions.scm")
(timed-prime-test 100003)
(timed-prime-test 100019)
(timed-prime-test 100043)
(timed-prime-test 1000003)
(timed-prime-test 1000033)
(timed-prime-test 1000037)
(timed-prime-test 10000019)
(timed-prime-test 10000079)
(timed-prime-test 10000103)
(timed-prime-test 100000007)
(timed-prime-test 100000037)
(timed-prime-test 100000039)
#+end_src

#+RESULTS:
#+begin_example
100003 | 14723
100019 | 28481
100043 | 6019
1000003 | 4187
1000033 | 4104
1000037 | 4228
10000019 | 6296
10000079 | 5024
10000103 | 4929
100000007 | 5661
100000037 | 5435
100000039 | 7817
#+end_example

\[
D_n = \frac{T3_n}{T2_n} - \frac{\log{n}}{\sqrt{n}}
\]

|         n | T2_n (ns) | T3_n (ns) |         D_n |
|-----------+-----------+-----------+-------------|
|    100003 |     28128 |      1472 | 0.015925580 |
|    100019 |     10090 |      2848 |  0.24585545 |
|    100043 |     10186 |      6019 |  0.55450849 |
|   1000003 |     29715 |      4187 |  0.12708977 |
|   1000033 |     29531 |      4104 |  0.12515729 |
|   1000037 |     29554 |      4228 |  0.12924487 |
|  10000019 |     91376 |      6296 | 0.063805134 |
|  10000079 |     91356 |      5024 | 0.049896679 |
|  10000103 |     91318 |      4929 | 0.048879249 |
| 100000007 |    289935 |      5661 | 0.017682998 |
| 100000037 |    289866 |      5435 | 0.016907975 |
| 100000039 |    301755 |      7817 | 0.024063054 |
#+tblfm: $4=$3/$2 - log($1)/sqrt($1)

* Exercise 1.25
Alyssa P. Hacker complains that we went to a lot of extra work in writing expmod. After all, she says, since we already know how to compute exponentials, we could have simply written

#+begin_src scheme :eval never
(define (expmod base exp m)
  (remainder (fast-expt base exp) m))
#+end_src

Is she correct? Would this procedure serve as well for our fast prime tester? Explain.

** Solution
While mathematically both functions are equivalent, Alissa P Hacker solution will produce very large intermediate results that will slowdown the computation or even make the calculation impractical.

* Exercise 1.26
Louis Reasoner is having great difficulty doing Exercise 1.24. His fast-prime? test seems to run more slowly than his prime? test. Louis calls his friend Eva Lu Ator over to help. When they examine Louis’s code, they find that he has rewritten the expmod procedure to use an explicit multiplication, rather than calling square:

#+begin_src scheme :eval never
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder
          (* (expmod base (/ exp 2) m)
             (expmod base (/ exp 2) m))
          m))
        (else
         (remainder
          (* base
             (expmod base (- exp 1) m))
          m))))
#+end_src

“I don’t see what difference that could make,” says Louis. “I do.” says Eva. “By writing the procedure like that, you have transformed the $\theta(log n)$ process into a $\theta(n)$ process.” Explain.

** Solution
expmod will be evaluated twice for even exponents nullifying the effect of dividing the exponent by 2. In other words expmod will be evaluated n times.

* Exercise 1.27
Demonstrate that the Carmichael numbers listed in Footnote 47 really do fool the Fermat test. That is, write a procedure that takes an integer n and tests whether $a^n$ is congruent to a modulo n for every $a < n$, and try your procedure on the given Carmichael numbers.

** Solution
#+begin_src scheme
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder
          (square (expmod base (/ exp 2) m))
          m))
        (else
         (remainder
          (* base (expmod base (- exp 1) m))
          m))))

(define (exaustive-fermat-test n)
  (define (exaustive-fermat-test-iter n a)
    (cond ((= n a) #t)
          ((= (expmod a n n) a)
           (exaustive-fermat-test-iter n (inc a)))
          (else #f)))
  (exaustive-fermat-test-iter n 1))

(test-assert (exaustive-fermat-test 561))
(test-assert (exaustive-fermat-test 1105))
(test-assert (exaustive-fermat-test 1729))
(test-assert (exaustive-fermat-test 2465))
(test-assert (exaustive-fermat-test 2821))
(test-assert (exaustive-fermat-test 6601))
#+end_src

* Exercise 1.28
One variant of the Fermat test that cannot be fooled is called the Miller-Rabin test (Miller 1976; Rabin 1980). This starts from an alternate form of Fermat’s Little Theorem, which states that if n is a prime number and a is any positive integer less than n, then a raised to the \((n-1)\)-st power is congruent to 1 modulo n. To test the primality of a number n by the Miller-Rabin test, we pick a random number $a < n$ and raise a to the \((n-1)\)-st power modulo n using the expmod procedure. However, whenever we perform the squaring step in expmod, we check to see if we have discovered a “nontrivial square root of 1 modulo n,” that is, a number not equal to 1 or $n-1$ whose square is equal to 1 modulo n. It is possible to prove that if such a nontrivial square root of 1 exists, then n is not prime. It is also possible to prove that if n is an odd number that is not prime, then, for at least half the numbers $a<n$, computing $a^{n-1}$ in this way will reveal a nontrivial square root of 1 modulo n. (This is why the Miller-Rabin test cannot be fooled.) Modify the expmod procedure to signal if it discovers a nontrivial square root of 1, and use this to implement the Miller-Rabin test with a procedure analogous to fermat-test. Check your procedure by testing various known primes and non-primes. Hint: One convenient way to make expmod signal is to have it return 0.

** Solution
#+begin_src scheme
(define (guess-a n)
  (+ 1 (random (- n 1))))

(define (check-non-trivial-sqrt-mod x n m)
  (if (and
       (= x 1)
       (not (= n 1))
       (not (= n (- m 1))))
      0
      x))

(define (sqrmod-check n m)
  (check-non-trivial-sqrt-mod (remainder (square n) m) n m))

(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (sqrmod-check (expmod base (/ exp 2) m) m))
        (else
         (remainder
          (* base (expmod base (- exp 1) m))
          m))))

(define (miller-rabin-test n)
  (= 1 (expmod (guess-a n) (- n 1) n)))

(test-assert (miller-rabin-test 11))
(test-assert (miller-rabin-test 23))
(test-assert (miller-rabin-test 100003))
(test-assert (miller-rabin-test 100019))
(test-assert (miller-rabin-test 100043))
(test-assert (miller-rabin-test 1000003))
(test-assert (miller-rabin-test 1000033))
(test-assert (miller-rabin-test 1000037))
(test-assert (miller-rabin-test 10000019))
(test-assert (miller-rabin-test 10000079))
(test-assert (miller-rabin-test 10000103))
(test-assert (miller-rabin-test 100000007))
(test-assert (miller-rabin-test 100000037))
(test-assert (miller-rabin-test 100000039))
(test-assert (not (miller-rabin-test 561)))
(test-assert (not (miller-rabin-test 1105)))
(test-assert (not (miller-rabin-test 1729)))
(test-assert (not (miller-rabin-test 2465)))
(test-assert (not (miller-rabin-test 2821)))
(test-assert (not (miller-rabin-test 6601)))
#+end_src

* Exercise 1.29
Simpson’s Rule is a more accurate method of numerical integration than the method illustrated above. Using Simpson’s Rule, the integral of a function f between a and b is approximated as \(\frac{h}{3}(y_0 + 4y_1 + 2y_2 + 4y_3 + 2y_4 + \cdots + 2y_{n-2} + 4y_{n-1} + y_n) \), where \(h = (b-a)/n \), for some even integer n, and $y_k = f(a+kh)$. (Increasing n increases the accuracy of the approximation.) Define a procedure that takes as arguments f, a, b, and n and returns the value of the integral, computed using Simpson’s Rule. Use your procedure to integrate cube between 0 and 1 (with $n=100$ and $n=1000$), and compare the results to those of the integral procedure shown above.

** Solution
#+begin_src scheme
(define (sum term a next b)
  (if (> a b)
      0
      (+ (term a)
         (sum term (next a) next b))))

(define (integral f a b n)
  (define h (/ (- b a) n))
  (define (y k) (f (+ a (* k h))))
  (define (term k) (* (y k) (+ 2 (* 2 (remainder k 2)))))
  (* (/ h 3) (+ (y 0) (y n) (sum term 1 inc (- n 1)))))

(test-equal (/ 1 4) (integral cube 0 1 100))
(test-equal (/ 1 4) (integral cube 0 1 1000))
#+end_src

* Exercise 1.30
The sum procedure above generates a linear recursion. The procedure can be rewritten so that the sum is performed iteratively. Show how to do this by filling in the missing expressions in the following definition:

#+begin_src scheme :eval never
(define (sum term a next b)
  (define (iter a result)
    (if ⟨??⟩
        ⟨??⟩
        (iter ⟨??⟩ ⟨??⟩)))
  (iter ⟨??⟩ ⟨??⟩))
#+end_src

** Solution
#+begin_src scheme
(define (sum term a next b)
  (define (iter a result)
    (if (> a b)
        result
        (iter (next a) (+ result (term a)))))
  (iter a 0))

(test-equal 55 (sum identity 1 inc 10))
#+end_src

* Exercise 1.31
1. The sum procedure is only the simplest of a vast number of similar abstractions that can be captured as higher-order procedures.51 Write an analogous procedure called product that returns the product of the values of a function at points over a given range. Show how to define factorial in terms of product. Also use product to compute approximations to $\pi$ using the formula

\[
\frac{\pi}{4} =
\frac{2 \cdot 4 \cdot 4 \cdot 6 \cdot 6 \cdot 8 \cdot \cdots}
     {3 \cdot 3 \cdot 5 \cdot 5 \cdot 7 \cdot 7 \cdot \cdots}.
\]

2. If your product procedure generates a recursive process, write one that generates an iterative process. If it generates an iterative process, write one that generates a recursive process.

** Solution
*** Recursive
#+name recursive pi-approx
#+begin_src scheme
(define (product term a next b)
  (if (> a b)
      1
      (* (term a)
         (product term (next a) next b))))

(define (pi-approx n)
  (define (inc n) (+ n 1))
  (define (term n)
    (define n+1 (+ n 1.0))
    (/
     (+ n+1 (remainder n+1 2))
     (+ n+1 (remainder n 2))))
  (* 4 (product term 1 inc n)))

(test-approximate 3.141 (pi-approx 10000) 0.001)
#+end_src

*** Iterative
#+name iterative pi-approx
#+begin_src scheme
(define (product term a next b)
  (define (iter a result)
    (if (> a b)
        result
        (iter (next a) (* result (term a)))))
  (iter a 1))

(define (pi-approx n)
  (define (inc n) (+ n 1))
  (define (term n)
    (define n+1 (+ n 1.0))
    (/
     (+ n+1 (remainder n+1 2))
     (+ n+1 (remainder n 2))))
  (* 4 (product term 1 inc n)))

(test-approximate 3.141 (pi-approx 10000) 0.001)
#+end_src

* Exercise 1.32
1. Show that sum and product (Exercise 1.31) are both special cases of a still more general notion called accumulate that combines a collection of terms, using some general accumulation function:
   #+begin_src scheme :eval never
   (accumulate
    combiner null-value term a next b)
   #+end_src
   Accumulate takes as arguments the same term and range specifications as sum and product, together with a combiner procedure (of two arguments) that specifies how the current term is to be combined with the accumulation of the preceding terms and a null-value that specifies what base value to use when the terms run out. Write accumulate and show how sum and product can both be defined as simple calls to accumulate.

2. If your accumulate procedure generates a recursive process, write one that generates an iterative process. If it generates an iterative process, write one that generates a recursive process.

** Solution
*** Recursive
#+begin_src scheme
(define (accumulate combiner null-value term a next b)
  (if (> a b)
      null-value
      (combiner
       (term a)
       (accumulate combiner null-value term (next a) next b))))

(define (product term a next b)
  (accumulate * 1 term a next b))
(define (sum term a next b)
  (accumulate + 0 term a next b))

(define (factorial n)
  (product identity 1 inc n))
(define (sum-of-naturals n)
  (sum identity 1 inc n))

(test-equal 120 (factorial 5))
(test-equal 15  (sum-of-naturals 5))
#+end_src

*** Iterative
#+begin_src scheme
(define (accumulate combiner null-value term a next b)
  (define (iter a result)
    (if (> a b)
        result
        (iter (next a) (combiner result (term a)))))
  (iter a null-value))

(define (product term a next b)
  (accumulate * 1 term a next b))
(define (sum term a next b)
  (accumulate + 0 term a next b))

(define (factorial n)
  (product identity 1 inc n))
(define (sum-of-naturals n)
  (sum identity 1 inc n))

(test-equal 120 (factorial 5))
(test-equal 15  (sum-of-naturals 5))
#+end_src

* Exercise 1.33
You can obtain an even more general version of accumulate (Exercise 1.32) by introducing the notion of a filter on the terms to be combined. That is, combine only those terms derived from values in the range that satisfy a specified condition. The resulting filtered-accumulate abstraction takes the same arguments as accumulate, together with an additional predicate of one argument that specifies the filter. Write filtered-accumulate as a procedure. Show how to express the following using filtered-accumulate:
1. the sum of the squares of the prime numbers in the interval a to b (assuming that you have a prime? predicate already written)
2. the product of all the positive integers less than n that are relatively prime to n (i.e., all positive integers $i<n$ such that $GCD(i,n)=1$).

** Solution
#+begin_src scheme
(load-from-path "1_33-definitions.scm")
(define (filtered-accumulate predicate combiner null-value term a next b)
  (define (evaluate-result result value)
    (if (not (predicate value))
        result
        (combiner result value)))
  (define (iter a result)
    (if (> a b)
        result
        (iter (next a) (evaluate-result result (term a)))))
  (iter a null-value))

(define (sum-of-squares-of-primes a b)
  (define (sum-square r n)
    (+ r (square n)))
  (filtered-accumulate prime? sum-square 0 identity a inc b))

(define (product-of-coprimes n)
  (define (coprime? a) (= 1 (gcd a n)))
  (filtered-accumulate coprime? * 1 identity 2 inc (- n 1)))

(test-equal 87 (sum-of-squares-of-primes 2 7))
(test-equal 5 (product-of-coprimes 6))
#+end_src

* Exercise 1.34
Suppose we define the procedure
#+begin_src scheme :eval never
(define (f g) (g 2))
#+end_src
Then we have
#+begin_example
(f square)
4

(f (lambda (z) (* z (+ z 1))))
6
#+end_example
What happens if we (perversely) ask the interpreter to evaluate the combination (f f)? Explain.

** Solution
It will expand to (2 2) and raise an error trying to execute 2 as a procedure.

* Exercise 1.35
Show that the golden ratio $\varphi$ (1.2.2) is a fixed point of the transformation $x \mapsto 1 + 1/x$, and use this fact to compute $\varphi$ by means of the fixed-point procedure.

** Solution
Given that $\varphi$ solves the equation $x^2 = x + 1$, see solution of 1.15, then
\[ \varphi = \frac{\varphi + 1}{\varphi} \]
\[ \varphi =  1 + \frac{1}{\varphi} \]

#+begin_src scheme
(define tolerance 0.00001)
(define (fixed-point f first-guess)
  (define (close-enough? v1 v2)
    (< (abs (- v1 v2))
       tolerance))
  (define (try guess)
    (let ((next (f guess)))
      (if (close-enough? guess next)
          next
          (try next))))
  (try first-guess))

(define (approximate-phi)
  (fixed-point
   (lambda (x) (+ 1 (/ 1 x)))
   1.0))

(test-approximate 1.61803 (approximate-phi) tolerance)
#+end_src

* Exercise 1.36
Modify fixed-point so that it prints the sequence of approximations it generates, using the newline and display primitives shown in Exercise 1.22. Then find a solution to $x^x = 1000$ by finding a fixed point of $x \mapsto log(1000)/log(x)$. (Use Scheme’s primitive log procedure, which computes natural logarithms.) Compare the number of steps this takes with and without average damping. (Note that you cannot start fixed-point with a guess of 1, as this would cause division by $log(1)=0$.)

** Solution
#+begin_src scheme
(define tolerance 0.00001)
(define (fixed-point f first-guess)
  (define (close-enough? v1 v2)
    (< (abs (- v1 v2))
       tolerance))
  (define (try guess n)
    (display "try #")
    (display n)
    (display ": ")
    (display guess)
    (newline)
    (let ((next (f guess)))
      (if (close-enough? guess next)
          next
          (try next (inc n)))))
  (try first-guess 1))

(define (average x y) (/ (+ x y) 2))

(display "Without average damping")
(newline)
(display (fixed-point
          (lambda (x)
            (/ (log 1000) (log x)))
          10.0))
(newline)

(newline)
(display "With average damping")
(newline)
(display (fixed-point
          (lambda (x)
            (average x (/ (log 1000) (log x))))
          10.0))
(newline)
#+end_src

#+RESULTS:
#+begin_example
Without average damping
try #1: 10.0
try #2: 2.9999999999999996
try #3: 6.2877098228681545
try #4: 3.7570797902002955
try #5: 5.218748919675316
try #6: 4.1807977460633134
try #7: 4.828902657081293
try #8: 4.386936895811029
try #9: 4.671722808746095
try #10: 4.481109436117821
try #11: 4.605567315585735
try #12: 4.522955348093164
try #13: 4.577201597629606
try #14: 4.541325786357399
try #15: 4.564940905198754
try #16: 4.549347961475409
try #17: 4.5596228442307565
try #18: 4.552843114094703
try #19: 4.55731263660315
try #20: 4.554364381825887
try #21: 4.556308401465587
try #22: 4.555026226620339
try #23: 4.55587174038325
try #24: 4.555314115211184
try #25: 4.555681847896976
try #26: 4.555439330395129
try #27: 4.555599264136406
try #28: 4.555493789937456
try #29: 4.555563347820309
try #30: 4.555517475527901
try #31: 4.555547727376273
try #32: 4.555527776815261
try #33: 4.555540933824255
4.555532257016376

With average damping
try #1: 10.0
try #2: 6.5
try #3: 5.095215099176933
try #4: 4.668760681281611
try #5: 4.57585730576714
try #6: 4.559030116711325
try #7: 4.55613168520593
try #8: 4.555637206157649
try #9: 4.55555298754564
try #10: 4.555538647701617
4.555536206185039
#+end_example

* Exercise 1.37
1. An infinite continued fraction is an expression of the form
   \[
   f = \frac{N_1}{D_1 + \frac{N_2}{D_2 + \frac{N_3}{D_3 + \cdots}}}.
   \]
   As an example, one can show that the infinite continued fraction expansion with the $N_i$ and the $D_i$ all equal to 1 produces $1/\varphi$, where $\varphi$ is the golden ratio (described in 1.2.2). One way to approximate an infinite continued fraction is to truncate the expansion after a given number of terms. Such a truncation-a so-called finite continued fraction k-term finite continued fraction-has the form
   \[
   \frac{N_1}{D_1 + \frac{N_2}{\ddots + \frac{N_k}{D_k}}}.
   \]
   Suppose that n and d are procedures of one argument (the term index i) that return the $N_i$ and $D_i$ of the terms of the continued fraction. Define a procedure cont-frac such that evaluating (cont-frac n d k) computes the value of the k-term finite continued fraction. Check your procedure by approximating $1/\varphi$ using
   #+begin_src scheme :eval never
   (cont-frac (lambda (i) 1.0)
              (lambda (i) 1.0)
              k)
   #+end_src
   for successive values of k. How large must you make k in order to get an approximation that is accurate to 4 decimal places?

2. If your cont-frac procedure generates a recursive process, write one that generates an iterative process. If it generates an iterative process, write one that generates a recursive process.

** Solution
*** Recursive
#+begin_src scheme
(define (cont-frac n d k)
  (define (recurse i)
    (if (= i k)
        (/ (n k) (d k))
        (/ (n i) (+ (d i) (recurse (+ i 1))))))
  (recurse 1))

(define (search-k-approx f start target error)
  (if (<
       (abs (- (f start) target))
       error)
  start
  (search-k-approx f (+ start 1) target error)))

(display (search-k-approx
          (lambda (k)
            (cont-frac
             (lambda (i) 1.0)
             (lambda (i) 1.0)
             k))
         3
         0.61803398
         0.0001))
#+end_src

#+RESULTS:
: 10

*** Iterative
#+begin_src scheme
(define (cont-frac n d k)
  (define (iter k result)
    (if (= k 0)
        result
        (iter
         (- k 1)
         (/ (n k)
            (+ (d k) result)))))
  (iter (- k 1) (/ (n k) (d k))))

(define (search-k-approx f start target error)
  (if (<
       (abs (- (f start) target))
       error)
  start
  (search-k-approx f (+ start 1) target error)))

(display
 (search-k-approx
  (lambda (k)
    (cont-frac
     (lambda (i) 1.0)
     (lambda (i) 1.0)
     k))
  3
  0.61803398
  0.0001))
#+end_src

#+RESULTS:
: 10

* Exercise 1.38
In 1737, the Swiss mathematician Leonhard Euler published a memoir De Fractionibus Continuis, which included a continued fraction expansion for $e-2$, where $e$ is the base of the natural logarithms. In this fraction, the $N_i$ are all 1, and the $D_i$ are successively $1, 2, 1, 1, 4, 1, 1, 6, 1, 1, 8, \cdots$. Write a program that uses your cont-frac procedure from Exercise 1.37 to approximate $e$, based on Euler’s expansion.

** Solution
#+begin_src scheme
(define (cont-frac n d k)
  (define (iter k result)
    (if (= k 0)
        result
        (iter
         (- k 1)
         (/ (n k)
            (+ (d k) result)))))
  (iter (- k 1) (/ (n k) (d k))))

(test-approximate 0.71828
  (cont-frac
   (lambda (i) 1.0)
   (lambda (i)
     (if (= (remainder i 3) 2)
         (* 2 (+ (quotient i 3) 1))
         1.0))
   12)
  0.00001)
#+end_src

* Exercise 1.39
A continued fraction representation of the tangent function was published in 1770 by the German mathematician J.H. Lambert:
\[
\tan{x} = \frac{x}{1 - \frac{x^2}{3 - \frac{x^2}{5 - \cdots}}},
\]
where $x$ is in radians. Define a procedure (tan-cf x k) that computes an approximation to the tangent function based on Lambert’s formula. k specifies the number of terms to compute, as in Exercise 1.37.

** Solution
#+begin_src scheme
(define (cont-frac n d k)
  (define (recurse i)
    (if (= i k)
        (/ (n k) (d k))
        (/ (n i) (+ (d i) (recurse (+ i 1))))))
  (recurse 1))

(define (tan-cf x k)
  (cont-frac
      (lambda (i)
        (if (= i 1)
            x
            (- (* x x))))
      (lambda (i)
        (- (* i 2) 1))
      k))

(test-approximate (tan 0.0) (tan-cf 0.0 10) 0.0001)
(test-approximate (tan 1.0) (tan-cf 1.0 10) 0.0001)
(test-approximate (tan 2.0) (tan-cf 2.0 10) 0.0001)
(test-approximate (tan 3.14159) (tan-cf 3.14159 10) 0.0001)
#+end_src

* Exercise 1.40
Define a procedure cubic that can be used together with the newtons-method procedure in expressions of the form
#+begin_src scheme :eval never
(newtons-method (cubic a b c) 1)
#+end_src
to approximate zeros of the cubic $x^3+ax^2+bx+c$.

** Solution
#+begin_src scheme
(define (fixed-point f first-guess)
  (define (close-enough? v1 v2)
    (< (abs (- v1 v2))
       0.00001))
  (define (try guess)
    (let ((next (f guess)))
      (if (close-enough? guess next)
          next
          (try next))))
  (try first-guess))

(define (deriv g dx)
  (lambda (x)
    (/ (- (g (+ x dx)) (g x))
       dx)))

(define (newton-transform g)
  (lambda (x)
    (- x (/ (g x)
            ((deriv g 0.00001) x)))))

(define (newtons-method g guess)
  (fixed-point (newton-transform g)
               guess))

(define (cubic a b c)
  (lambda (x)
    (+ (cube x) (* a (square x)) (* b x) c)))

(test-approximate 0.0
  (let ((f (cubic 5 7 11)))
    (f (newtons-method f 1.0)))
  0.00001)
#+end_src

* Exercise 1.41
Define a procedure double that takes a procedure of one argument as argument and returns a procedure that applies the original procedure twice. For example, if inc is a procedure that adds 1 to its argument, then (double inc) should be a procedure that adds 2. What value is returned by
#+begin_src scheme :eval never
(((double (double double)) inc) 5)
#+end_src

** Solution
#+begin_src scheme
(define (double f)
  (lambda (x)
    (f (f x))))

(test-equal 3 ((double inc) 1))
(test-equal 21 (((double (double double)) inc) 5))
#+end_src

* Exercise 1.42
Let $f$ and $g$ be two one-argument functions. The composition $f$ after $g$ is defined to be the function $x \mapsto f(g(x))$. Define a procedure compose that implements composition. For example, if inc is a procedure that adds 1 to its argument,
#+begin_src scheme :eval never
((compose square inc) 6)
49
#+end_src

** Solution
#+begin_src scheme
(define (compose f g)
  (lambda (x) (f (g x))))

(test-equal 49 ((compose square inc) 6))
#+end_src

* Exercise 1.43
If $f$ is a numerical function and $n$ is a positive integer, then we can form the $n^{th}$ repeated application of $f$, which is defined to be the function whose value at $x$ is $f(f(\cdots(f(x))\cdots))$. For example, if $f$ is the function $x \mapsto x+1$, then the $n^{th}$ repeated application of $f$ is the function $x \mapsto x+n$. If $f$ is the operation of squaring a number, then the $n^{th}$ repeated application of $f$ is the function that raises its argument to the $2^n$-th power. Write a procedure that takes as inputs a procedure that computes $f$ and a positive integer $n$ and returns the procedure that computes the $n^{th}$ repeated application of $f$. Your procedure should be able to be used as follows:
#+begin_src scheme
((repeated square 2) 5)
625
#+end_src
Hint: You may find it convenient to use compose from Exercise 1.42.

** Solution
*** Using compose
**** iterative
#+begin_src scheme
(define (compose f g)
  (lambda (x) (f (g x))))

(define (repeated f n)
  (define (iter i composed)
    (if (= i n)
        composed
        (iter (inc i) (compose f composed))))
  (iter 1 f))

(test-equal 625 ((repeated square 2) 5))
#+end_src

**** recursive
#+begin_src scheme
(define (compose f g)
  (lambda (x) (f (g x))))

(define (repeated f n)
  (if (= n 1)
      f
      (compose f (repeated f (dec n)))))

(test-equal 625 ((repeated square 2) 5))
#+end_src

*** Not using compose
**** iterative
#+begin_src scheme
(define (repeated f n)
  (define (iter i result)
    (if (= i n)
        result
        (iter (inc i) (f result))))
  (lambda (x)
    (iter 0 x)))

(test-equal 625 ((repeated square 2) 5))
#+end_src

**** recursive
#+begin_src scheme
(define (repeated f n)
  (lambda (x)
    (define (recur n)
      (if (= n 1)
          (f x)
          (f (recur (dec n)))))
    (recur n)))

(test-equal 625 ((repeated square 2) 5))
#+end_src

* Exercise 1.44
The idea of smoothing a function is an important concept in signal processing. If $f$ is a function and $dx$ is some small number, then the smoothed version of $f$ is the function whose value at a point $x$ is the average of $f(x-dx)$, $f(x)$, and $f(x+dx)$. Write a procedure smooth that takes as input a procedure that computes $f$ and returns a procedure that computes the smoothed $f$. It is sometimes valuable to repeatedly smooth a function (that is, smooth the smoothed function, and so on) to obtain the n-fold smoothed function. Show how to generate the n-fold smoothed function of any given function using smooth and repeated from Exercise 1.43.

** Solution
#+begin_src scheme
;; from 1.43
(define (compose f g)
  (lambda (x) (f (g x))))

(define (repeated f n)
  (if (= n 1)
      f
      (compose f (repeated f (dec n)))))

;; 1.44 solution
(define (smooth f)
  (lambda (x)
    (let ((dx 0.00001))
     (/
      (+ (f (- x dx)) (f x) (f (+ x dx)))
      3))))

(define (n-fold-smooth f n)
  ((repeated smooth n) f))

(test-approximate 4 ((smooth square) 2) 0.0001)
(test-approximate 4 ((n-fold-smooth square 3) 2) 0.0001)
#+end_src

* Exercise 1.45
We saw in 1.3.3 that attempting to compute square roots by naively finding a fixed point of $y \mapto x/y does not converge, and that this can be fixed by average damping. The same method works for finding cube roots as fixed points of the average-damped $y \mapto x/y^2$. Unfortunately, the process does not work for fourth roots - a single average damp is not enough to make a fixed-point search for $y \mapto x/y^3$ converge. On the other hand, if we average damp twice (i.e., use the average damp of the average damp of $y \mapto x/y^3$) the fixed-point search does converge. Do some experiments to determine how many average damps are required to compute n^{th} roots as a fixed-point search based upon repeated average damping of $y \mapto x/y^{n-1}$.. Use this to implement a simple procedure for computing n^{th} roots using fixed-point, average-damp, and the repeated procedure of Exercise 1.43. Assume that any arithmetic operations you need are available as primitives.

** Solution
#+begin_src scheme
;; from book samples
(define tolerance 0.0001)
(define (fixed-point f first-guess)
  (define (close-enough? v1 v2)
    (< (abs (- v1 v2))
       tolerance))
  (define (try guess)
    (let ((next (f guess)))
      (if (close-enough? guess next)
          next
          (try next))))
  (try first-guess))

(define (average x y)
  (/ (+ x y) 2))

(define (average-damp f)
  (lambda (x)
    (average x (f x))))

;; from 1.43
(define (compose f g)
  (lambda (x) (f (g x))))

(define (repeated f n)
  (if (= n 1)
      f
      (compose f (repeated f (dec n)))))

;; actual solution
(define (halve n)
    (if (even? n)
        (/ n 2)
        (/ (- n 1) 2)))

(define (root n x)
  (fixed-point
   ((repeated average-damp (halve n))
    (lambda (y)
      (/ x (expt y (- n 1)))))
   1.0))

(test-approximate 13 (root 4  (expt 13 4))  0.00001)
(test-approximate 13 (root 8  (expt 13 8))  0.0001)
(test-approximate 13 (root 16 (expt 13 16)) 0.01)
#+end_src

* Exercise 1.46
Several of the numerical methods described in this chapter are instances of an extremely general computational strategy known as iterative improvement. Iterative improvement says that, to compute something, we start with an initial guess for the answer, test if the guess is good enough, and otherwise improve the guess and continue the process using the improved guess as the new guess. Write a procedure iterative-improve that takes two procedures as arguments: a method for telling whether a guess is good enough and a method for improving a guess. Iterative-improve should return as its value a procedure that takes a guess as argument and keeps improving the guess until it is good enough. Rewrite the sqrt procedure of 1.1.7 and the fixed-point procedure of 1.3.3 in terms of iterative-improve.

** Solution
#+begin_src scheme
(define (iterative-improve test improve)
  (define (iter guess)
    (if (test guess)
        guess
        (iter (improve guess))))
  (lambda (guess)
    (iter guess)))

;; refactored sqrt
(define (sqrt x)
  (define (good-enough? guess)
    (< (abs (- (square guess) x)) 0.001))
  (define (improve guess)
    (average guess (/ x guess)))
  ((iterative-improve good-enough? improve)
   1.0))

;; test sqrt
(test-approximate 1.4142 (sqrt 2) 0.0001)

;; refactored fixed-point
(define (fixed-point f first-guess)
  (define (close-enough? v1 v2)
    (< (abs (- v1 v2))
       0.00001))
  ((iterative-improve
    (lambda (guess)
      (close-enough? guess (f guess)))
    f)
   first-guess))

;; test fixed-point
(define (approximate-phi)
  (fixed-point
   (lambda (x) (+ 1 (/ 1 x)))
   1.0))

(test-approximate 1.61803 (approximate-phi) 0.00001)
#+end_src

* meta                                                             :noexport:
#+PROPERTY: header-args :results output
#+OPTIONS: todo:nil toc:nil num:nil
#+HTML_HEAD_EXTRA: <style> img { width: 100% }</style>
# Local Variables:
# eval: (olivetti-mode 1)
# eval: (flyspell-mode 1)
# ispell-local-dictionary: "american"
# eval: (advice-add
#        'org-babel-insert-result
#        :filter-args
#        (lambda (args)
#          (let ((result (car args))
#                (result-params (cadr args))
#                (others (cddr args)))
#            (apply 'list
#                   result
#                   (if (or
#                        (string-empty-p result) (not result))
#                       (progn (org-babel-remove-result) '("silent"))
#                     result-params)
#                   others))))
# eval: (add-hook 'geiser-repl-startup-hook
#        (lambda ()
#          (geiser-load-file "chapter-1-defs.scm")))
# End:
